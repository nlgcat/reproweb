# The ReproHum Project
The ReproHum projects aims to define, measure, and improve reproducibility in the field of Natural Language Processing.  The project is funded under [EPSRC grant EP/V05645X/1](https://gow.epsrc.ukri.org/NGBOViewGrant.aspx?GrantRef=EP/V05645X/1).  Reproducibility is one of the cornerstones of scientific research yet experimentla results for NLP systems are seldom reproduced.  Even when they are, results tend to be worse than in the original publication.

The ReproHum project aims improve the current reproducibility situation in NLP.  The main goals are:
1. Develop a methodological framework from testing the reproducibility of human evaluations in NLP.
2. Design then perform a multi-lab study where partner labs reproduce human evaluation results from the last 10 years, covering a variety of areas within NLP.
3. Provide guidance on reproducibility to the NLP community and build a concensus within the community on how NLP as a field can continue to improve in this regard.


## Organisers
[Anya Belz](https://www.adaptcentre.ie/experts/anya-belz):  Principal Investigator - ADAPT Research Centre, Dublin City University; University of Aberdeen

[Ehud Reiter](https://www.abdn.ac.uk/ncs/profiles/e.reiter):  Co-Investigator - University of Aberdeen

[Craig Thomson](https://www.abdn.ac.uk/people/c.thomson):  Research Assistant - University of Aberdeen


## Survey for NLP researchers
We will shortly be conducting a surveys on the attitudes towards reproducibility in NLP, as well as the barriers that are faced by researchers.


## Multi-lab Study
A major part of the ReproHum project is a large multi-lab study where partner labs from across the world will reproduce results from a variety of papers from the last 10 years.  We are still open to new partner labs joining, please contact the organisers (links above).

... what are the reqs?  A faculty memeber to be the primary contact?
... partners provide time, and optionally funding for any experiments they perform (how do we word this?)


## ReproGen
The ReproGen shared task was first run as [ReproGen 2021](https://reprogen.github.io/2021) and is being run again as [ReproGen 2022](https://reprogen.github.io).  There are two tracks, one where participants can attempt reproduction of human or automated evaluations from a common list of published papers, and a second where participants can reproduct their own prior work.


## Coefficient of Variation
To measure the 


## ReproHum Papers


## Other relevant papers

